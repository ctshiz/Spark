{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark Stream with Pyspark 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcGq9RqwwYlq5iFw1bwXIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctshiz/WORKSPACE_SPARK/blob/main/Spark_Stream_with_Pyspark_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ViNjX-QhMvl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e8ec2e-219c-4178-efae-943281f15c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r0% [Connecting to archive.ubuntu.com] [1 InRelease 28.7 kB/88.7 kB 32%] [Connec\r0% [2 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com (91.189.91.38)]\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [2 InRelease gpgv 1,581 B] [Waiting for headers] [1 InRelease 51.8 kB/88.7 k\r0% [2 InRelease gpgv 1,581 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 1,581 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [2 InRelease gpgv 1,581 B] [5 InRelease 14.2 kB/88.7 kB 16%] [Waiting for he\r                                                                               \rGet:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [2 InRelease gpgv 1,581 B] [5 InRelease 15.6 kB/88.7 kB 18%] [6 InRelease 14\r                                                                               \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [817 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [85.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,901 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,063 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,527 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,304 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,105 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,333 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,075 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,063 kB]\n",
            "Fetched 16.5 MB in 4s (3,961 kB/s)\n",
            "Reading package lists... Done\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 37 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 39.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=c455cf40b8f4573a58a2612cbb62cffff53baab99d4f49cab0ffe09e864b5e92\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark[sql] in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (0.10.9.5)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (6.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->pyspark[sql]) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->pyspark[sql]) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->pyspark[sql]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.5->pyspark[sql]) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install pyspark[sql]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark =  SparkSession.builder.getOrCreate()\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/user/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n"
      ],
      "metadata": {
        "id": "YNUxflp1x4iP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read the files\n",
        "from pyspark.sql.functions import to_timestamp, col, lit\n",
        "df =  spark.read.csv('stream1.csv', header=True)\n",
        "df = df.drop(\"_c0\",\"isFraud\", \"isFlaggedFraud\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEvqJsKd7yM2",
        "outputId": "63bfbb54-702a-4db7-a0c1-5c02dc52af89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
            "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|\n",
            "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
            "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|\n",
            "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|\n",
            "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|\n",
            "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|\n",
            "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|\n",
            "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column **STEP** maps a unit of time in the real world. Let assume that 1 step is 1 hour of time. \n",
        "So we can assume for this example that we have another job that runs every hour and gets all the transactions in that time frame."
      ],
      "metadata": {
        "id": "Hfr-5oxHBqdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#count the transactions per step\n",
        "df.groupBy(\"step\").count().orderBy(\"count\", ascending=False).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqAow5Vi-qmd",
        "outputId": "87aedd9f-d94e-45c9-8f42-0fc51f055f43"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|step|count|\n",
            "+----+-----+\n",
            "|  19|51352|\n",
            "|  18|49579|\n",
            "|  15|44609|\n",
            "|  17|43361|\n",
            "|  16|42471|\n",
            "+----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can therefore sabe the output of that job by filtering on each step and saving it a separate file"
      ],
      "metadata": {
        "id": "BgQNu5U5HNDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "steps = df.select(\"step\").distinct().collect()\n",
        "for step in steps[:]:\n",
        "  _df = df.where(f\"step ={step[0]}\")\n",
        "  _df.coalesce(1).write.mode(\"append\").option(\"header\", \"true\").csv(\"data2/paysim\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-5DX29SDI72",
        "outputId": "ec5600d0-58a2-4a96-b537-e02cd7eef49b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 308 ms, sys: 25 ms, total: 333 ms\n",
            "Wall time: 37.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STREAMING**"
      ],
      "metadata": {
        "id": "FrA73UumLspR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's "
      ],
      "metadata": {
        "id": "eJ7Cuof9Lubh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pe-wmAe0Hf8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}